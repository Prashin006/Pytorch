{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bedc47d-8679-4853-b8ad-e5952b9fe309",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Imports to test the conda environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b71ba2d-43f5-4afa-8a49-2edeb4c41515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb5a3447-7af9-466f-95a1-560092aefd1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c1fa4d-02bb-4d07-b43d-51c1a607ea1a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Using MPS (Metal Performance Shaders) for utilizing Mac GPU\n",
    "#### Note that the code in this section is specifically for checking whether it is running on a GPU or CPU\n",
    "#### Instead of `torch.backends.mps.is_available()` use `torch.cuda.is_available()` for systems using Nvidia GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e67a49dc-b114-4bfd-bb6f-063765e6c941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal Performance Shaders are available for this system and we are using it to improve performance!\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    print(\"Metal Performance Shaders are available for this system and we are using it to improve performance!\")\n",
    "else:\n",
    "    print(\"Oops! Metal Performance Shaders aren't available!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "514d61c2-a146-406c-a455-936197f22d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is MPS built? True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Is MPS built? {torch.backends.mps.is_built()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16a72ccd-4db6-4aad-8bc9-e5cf61826550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is MPS available? True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Is MPS available? {torch.backends.mps.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80132e7a-337f-4c92-b83b-09fec46d4802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps\n"
     ]
    }
   ],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f85f3ed-2f3a-4a12-9c4d-c94f12f188b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(size=(3,4)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f3a34fd-b20d-4740-89b3-2e696003d4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9897, 0.4534, 0.2045, 0.2258],\n",
       "        [0.4348, 0.7880, 0.7695, 0.9900],\n",
       "        [0.0504, 0.6211, 0.1999, 0.7149]], device='mps:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d54281c-05ee-4e0a-a708-1fd21ca00621",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Creating Scalars and Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3124d583-da59-4ea2-a340-871f841031e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfeb720d-b149-46f8-af18-40b79a6233fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7408f3fc-797e-4525-9e0b-0ab50635caa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get tensor back as Python int\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7170dc7-f725-49a0-bf1d-3634245785c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77dc644d-5b08-4416-8b55-3528cc343811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd29d7ba-f3cf-499e-89d9-df0bab22e4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d0918d-4e66-45aa-ae2f-9f2264a3053c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Creating MATRIX and TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe4da4ea-d688-4305-a741-73e431d60472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix\n",
    "MATRIX = torch.tensor([[7, 8],\n",
    "                       [9, 10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f445a069-fb86-44e4-a249-2ee703a853d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([2, 2]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim, MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cb3bc2c-19cb-48fe-bc84-baa5895974ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 3,  6,  9],\n",
       "         [ 2,  4, 56]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensors\n",
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                       [3, 6, 9],\n",
    "                       [2, 4, 56]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea1e9348-6061-43d2-bee9-b25cbe3243b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim, TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f36c0cb-3dfe-4afc-a66e-629d8f8c026f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1,  2,  3],\n",
       "         [ 3,  6,  9],\n",
       "         [ 2,  4, 56]]),\n",
       " tensor([3, 6, 9]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0], TENSOR[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8eeae132-f652-4068-99d2-341afcd931ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "520303f9-5551-4438-8a59-ad277d93de18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0][0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98c8631-2086-4c46-8031-b302dac0c6d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Creating Random Tensors\n",
    "#### Why random tensors?\n",
    "- Random tensors are important because the way many neural networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data\n",
    "- `Start with random nos => look at data => update the random nos => look at data => update the random nos ...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8303381c-da52-43a3-ad15-5a6e88914f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3704, 0.3976, 0.7295, 0.6906],\n",
       "        [0.0994, 0.2495, 0.8552, 0.4103],\n",
       "        [0.1878, 0.8833, 0.3063, 0.4573]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (3,4)\n",
    "random_tensor = torch.rand(3, 4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "958dd31d-8f95-404c-b419-71aa30c0ce05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([3, 4]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim, random_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14992697-54ee-4949-b4d4-7a47a24c820a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4169, 0.7871, 0.1354,  ..., 0.9015, 0.4159, 0.9461],\n",
       "         [0.5490, 0.7804, 0.6586,  ..., 0.2555, 0.0261, 0.1514],\n",
       "         [0.7321, 0.6204, 0.2681,  ..., 0.3313, 0.0168, 0.8562],\n",
       "         ...,\n",
       "         [0.4931, 0.3309, 0.7482,  ..., 0.0800, 0.2093, 0.9108],\n",
       "         [0.9082, 0.0161, 0.7472,  ..., 0.0468, 0.6335, 0.3757],\n",
       "         [0.4910, 0.9575, 0.4729,  ..., 0.1730, 0.8591, 0.1505]],\n",
       "\n",
       "        [[0.3891, 0.9254, 0.5381,  ..., 0.4580, 0.3809, 0.8713],\n",
       "         [0.8302, 0.9327, 0.1174,  ..., 0.2747, 0.2967, 0.1782],\n",
       "         [0.7567, 0.5474, 0.9281,  ..., 0.6253, 0.8674, 0.7973],\n",
       "         ...,\n",
       "         [0.3062, 0.1855, 0.0898,  ..., 0.4181, 0.7184, 0.6944],\n",
       "         [0.2851, 0.7456, 0.0183,  ..., 0.2270, 0.8886, 0.5008],\n",
       "         [0.2767, 0.9496, 0.1634,  ..., 0.2822, 0.0423, 0.7861]],\n",
       "\n",
       "        [[0.0536, 0.2219, 0.4693,  ..., 0.7994, 0.7010, 0.3359],\n",
       "         [0.8363, 0.0013, 0.3186,  ..., 0.2077, 0.2424, 0.1557],\n",
       "         [0.2419, 0.6566, 0.5390,  ..., 0.4653, 0.6090, 0.0583],\n",
       "         ...,\n",
       "         [0.8989, 0.4670, 0.4316,  ..., 0.5677, 0.0086, 0.6119],\n",
       "         [0.2853, 0.9332, 0.6754,  ..., 0.4178, 0.4162, 0.5268],\n",
       "         [0.7080, 0.9794, 0.5126,  ..., 0.9498, 0.8306, 0.1752]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor with a similar shape to an image tensor\n",
    "random_image_size_tensor = torch.rand(size=(3,224,224))  # height, width, color_channels (R, G, B)\n",
    "random_image_size_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b412e2-a123-42d6-9cfd-ffa17ef2a470",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Creating zeroes and ones tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f44f17b-c2da-4306-8df7-49b9f0ad59d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(3, 4)\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e5d2b68-230b-4113-8e65-610b2a64842d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros * random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6e51f7b-162e-412f-b328-b57db4ac87e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensor of ones\n",
    "ones = torch.ones(size=(3, 4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b9dce65-6611-4056-8703-7a9a37bd4b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones*random_tensor == random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa092dbf-f06b-4c87-9696-c80d5f2c8fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.float32, torch.float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype, zeros.dtype, random_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3f59b1-d496-4c86-9742-fcbf51d0f934",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Creating a range of tensors and tensor-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72d644f4-7609-4496-bd39-8794473df2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below range method is deprecated\n",
    "# torch.range(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f6477fa-5fbe-4180-b4db-3c7a222b31ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.int64, tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(1,10)\n",
    "a.dtype,a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5603035-5625-430c-ae3f-1163577a822d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,  77, 154, 231, 308, 385, 462, 539, 616, 693, 770, 847, 924])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_77 = torch.arange(start=0,end=1000,step=77)\n",
    "step_77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78cf9a19-b5a7-4dd4-ac0c-207c435d3b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), torch.int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros_like_77 = torch.zeros_like(input=step_77)\n",
    "zeros_like_77, zeros_like_77.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aea9a2ed-8860-413b-acb5-444f05e4e4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " torch.int64,\n",
       " 1,\n",
       " torch.Size([13]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_like_77 = torch.ones_like(input=step_77)\n",
    "ones_like_77, ones_like_77.dtype, ones_like_77.ndim, ones_like_77.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f2d9968-ad64-44f0-bc62-c56faae81ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1000 // 77"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd73ef7f-eff8-4db5-8a1a-fd3ba051b79d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Tensor Datatypes\n",
    "**Note:** Tensor Datatypes are one of the big 3 errors with Pytorch and Deep Learning that we may run into\n",
    "1. Tensors not on right datatype\n",
    "2. Tensors not in right shape\n",
    "3. Tensors not on right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7db2a457-1315-40d9-9e90-bef5c57a5870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.0000, 3.0000, 9.0000, 6.8000], device='mps:0'), torch.float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor = torch.tensor([1.0,3.0,9.0,6.8],\n",
    "                               dtype=torch.float32,  # what datatype is the tensor (eg, float32 or float16)\n",
    "                               device='mps',  # what device the tensor is on (eg, cpu, gpu)\n",
    "                               requires_grad=False)  # whether or not to track gradients with this tensor operations \n",
    "float_32_tensor, float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa486ff7-fdb3-49cc-af7e-26d36648840b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.0000, 3.0000, 9.0000, 6.8008], device='mps:0', dtype=torch.float16),\n",
       " device(type='mps', index=0),\n",
       " device(type='mps', index=0))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "float_16_tensor, float_16_tensor.device, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e57e5fe4-0eee-4f53-85c5-3f95b02b7f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  9.0000, 81.0000, 46.2453], device='mps:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor * float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ccdb097a-151d-4fb9-b7c8-cb7374e8a899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, device(type='mps', index=0))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_mul_tensor = float_16_tensor * float_32_tensor\n",
    "float_mul_tensor.dtype, float_mul_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4d77dfa-275b-41dd-abb5-89ff67089c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 9, 6], device='mps:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = float_32_tensor.type(torch.int32)\n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ba5c5fef-acf4-43ac-ad4c-3e7b7418409e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  9.0000, 81.0000, 40.8125], device='mps:0',\n",
       "       dtype=torch.float16)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor * float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b84da6a5-3d4b-4ff6-bf4e-25232b81b440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.0000,  9.0000, 81.0000, 40.8000], device='mps:0'), torch.float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_another_mul_tensor = int_32_tensor * float_32_tensor\n",
    "float_another_mul_tensor, float_another_mul_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7638086d-eeb9-4812-8c0d-5b1a310d218e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Getting Information From Tensors\n",
    "#### To get the datatype simply type `tensor.dtype`\n",
    "#### To get the shape of a tensor simply type `tensor.shape`\n",
    "#### To get the device of a tensor simply type `tensor.device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "da7f8987-1eb4-473d-b458-5e4e541a678a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8772, 0.6057, 0.9304, 0.0986],\n",
       "        [0.3825, 0.1345, 0.8387, 0.4931],\n",
       "        [0.8424, 0.1803, 0.3098, 0.9477]], device='mps:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor = torch.rand(size=(3, 4), device='mps')\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4c4e9f1f-6816-43e5-aa1e-07fda1418cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datatype\n",
    "some_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fd213820-afe3-400d-9f61-1a6b298a2f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4]), 2, torch.Size([3, 4]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape and no of dimensions\n",
    "some_tensor.size(), some_tensor.ndim, some_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da18a1d4-5129-4c90-b1a8-85987ab65589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device\n",
    "some_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ce1cfa-f13a-43e9-97d7-a31098db59ad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Manipulating Tensors (Tensor operations)\n",
    "Tensor Operations include:\n",
    "- Addition\n",
    "- Subtractions\n",
    "- Multiplication (element-wise)\n",
    "- Division\n",
    "- Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "564ff1a6-e23d-4a02-a5a9-8a611a2bfc0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13], device='mps:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor and add 10 to it\n",
    "tensor = torch.tensor([1, 2, 3], dtype=torch.int32, device='mps')\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4f2caf2e-c133-4aa2-a4b3-ba56a67dc3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30], device='mps:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply tensor by 10 and reassign it back\n",
    "tensor *= 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8e06d02a-5af0-4982-b4bd-9958a1c7d1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3.], device='mps:0'), torch.float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divide tensor by 10 and reassign it back\n",
    "tensor = tensor / 10\n",
    "tensor, tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "158e4201-faae-42cb-b15e-8f31558c7a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([100., 200., 300.], device='mps:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try out Pytorch built-in functions\n",
    "torch.mul(tensor, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a2f7a4d9-6b93-430c-a721-1b1d8eeb0cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], device='mps:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9eb4a7dd-c24b-4be2-993a-507e4e445dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0100, 0.0200, 0.0300], device='mps:0')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.div(tensor, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "46034521-a352-4888-80d5-01ce109b4c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1001., 1002., 1003.], device='mps:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(tensor, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fdaef2f2-40a2-4bf6-902d-1ed20b8c293d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.], device='mps:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.subtract(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fdcaa9ce-6c3b-4c31-9c56-5e1a6a00b6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], device='mps:0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50abe7ad-9d67-4137-b2d8-a8efb353f812",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Matrix Multiplication\n",
    "Two main ways of performing multiplication in neural networks and deep learning are:\n",
    "1. Element-wise multiplication\n",
    "2. Matrix Multiplication\n",
    "\n",
    "There are two main rules that need to be satisfied in order to perform matrix multiplication:\n",
    "1. **Inner dimensions** must match\n",
    "   * `(3, 2) @ (2, 3)` will work\n",
    "   * `(3, 2) @ (3, 2)` won't work`\n",
    "2. The resulting matrix has the shape of **outer dimensions**\n",
    "   * `(2, 3) @ (3, 2)` => `(2, 2)`\n",
    "   * `(3, 2) @ (2, 3)` => `(3, 3)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "243c0e27-129d-4610-b265-4123fb3bcf33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9066, 0.8338, 0.0409, 0.5889],\n",
       "        [0.3928, 0.3551, 0.1626, 0.7931],\n",
       "        [0.0115, 0.6469, 0.1099, 0.4169]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1 = torch.rand(size=(3,4))\n",
    "tensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1bfe17ee-f83d-4946-9cab-10a2b250c806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9852, 0.7669, 0.2201],\n",
       "        [0.2519, 0.7007, 0.7178],\n",
       "        [0.6732, 0.8972, 0.9946],\n",
       "        [0.7435, 0.9135, 0.4166]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2 = torch.rand(size=(4,3))\n",
    "tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "38a8b4eb-5ebe-4bcd-ba9a-1c0a73d29357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5686, 1.8541, 1.0840],\n",
       "        [1.1756, 1.4205, 0.8335],\n",
       "        [0.5583, 0.9416, 0.7499]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor3 = torch.matmul(tensor1, tensor2)\n",
    "tensor3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "87b57d3c-bcc0-4efb-84a4-b2eccfc4cbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten = torch.tensor([1, 2, 3], dtype=torch.int32)\n",
    "ten * ten  # element wise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6c8bea17-4d5a-4af7-a03c-09de37b16ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14, dtype=torch.int32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(ten, ten)  # matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e20be662-0768-4cfb-af60-f0ccf13367ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14, dtype=torch.int32)\n",
      "CPU times: user 546 μs, sys: 743 μs, total: 1.29 ms\n",
      "Wall time: 1.57 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "value = 0\n",
    "for i in range(len(ten)):\n",
    "    value += ten[i] * ten[i]\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "df693588-236b-480e-a5e0-d211ee4d4804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14, dtype=torch.int32) cpu\n",
      "CPU times: user 240 μs, sys: 157 μs, total: 397 μs\n",
      "Wall time: 272 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "value = torch.matmul(ten, ten)\n",
    "print(value, value.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8610353f-e0fc-492d-9baf-2ac47b8be487",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### One of the most common error in Deep Learning: shape errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f0f5af5a-da84-455a-a10d-3c447e548609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapes for matrix multiplication\n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]])\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11],\n",
    "                         [9, 12]])\n",
    "# Below line of code will give a RuntimeError as the shapes of the two tensors for multiplication do not match\n",
    "# torch.mm(tensor_A, tensor_B)  # torch.mm() is same as torch.matmul() (it's an alias for writing less code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d19b733-593a-4279-a932-663929d93062",
   "metadata": {},
   "source": [
    "To fix our tensor shape issues, we can manipulate the shape of one of our tensors using a **transpose**.<br />\n",
    "A **transpose** switches the axes or dimensions of a given tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "15a1bf49-f779-4bb5-834a-a4414ed2ebc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7, 10],\n",
       "         [ 8, 11],\n",
       "         [ 9, 12]]),\n",
       " tensor([[ 7,  8,  9],\n",
       "         [10, 11, 12]]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B, tensor_B.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c135fdce-2756-48e9-b0d6-007e888b6668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B.shape, tensor_B.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5449d29c-30bc-4b95-874a-e8a3b42167b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27,  30,  33],\n",
       "        [ 61,  68,  75],\n",
       "        [ 95, 106, 117]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(tensor_A, tensor_B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ca465259-9985-46c9-b5cb-ea0aa15b5b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tensor_A, tensor_B.T).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394a9196-230f-46b8-93fa-4062576c0151",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Finding the min, max, mean, sum etc. (Tensor Aggregation)\n",
    "**Note: the `torch.mean()` function requires a tensor of datatype float32 to work**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8adb66d4-8bc2-417d-85e3-94a1ef6da4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]),\n",
       " torch.Size([10]),\n",
       " torch.int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(start=0, end=100, step=10)\n",
    "x, x.size(), x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "610b3b5f-af90-4dd0-9db5-01103a466b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), torch.int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the min\n",
    "# min = torch.min(x)\n",
    "min = x.min()\n",
    "min, min.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "33b4fa33-2967-44ff-8aa8-4ae4e0157fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), torch.int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the max\n",
    "# max = torch.max(x)\n",
    "max = x.max()\n",
    "max, max.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1a02ba97-442f-417e-9a58-8e8bcf76f104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mean\n",
    "# mean = x.mean()\n",
    "# mean\n",
    "# Above lines of code won't work (not the right datatype => mean does not accept long or int64), so we need to typecast the datatype using the dtype keyword\n",
    "# mean function accepts only either a floating point or a complex datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7cc7b217-c423-4b8b-a7c9-5fb805e8a2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(45.)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean = x.mean(dtype=torch.float32)\n",
    "# mean = torch.mean(x, dtype=torch.float32)\n",
    "mean = x.type(torch.float32).mean()\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b9ac4286-5582-4b4e-9268-d219bcc94a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(450), tensor(450))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the Sum\n",
    "torch.sum(x), x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "323382ee-b27a-413e-989f-85f6a567501d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(40), tensor(40))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.median(x), x.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86c882c-db72-4276-9b7e-cb4f279f8225",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Finding positional min and max using argmin and argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8d2a714c-7f90-4357-8fbb-301f9a5261a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(8), tensor(0), tensor(90))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# argmin and argmax => index/position at which the min and max values occur in the tensor\n",
    "x.argmin(), a.argmax(), x[x.argmin()], x[x.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b97dc561-5e34-47f9-a1f3-60622402fd1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.arange(1, 100, step=10)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "af4ce398-b766-4b38-a007-24e7bd508f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(9))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.argmin(), y.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "27ce5e63-3ba8-48b0-9497-7955cb651d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1), tensor(91))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0], y[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2462db3b-eb02-4ba7-a55f-89138b84f5e0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Reshaping, Viewing, Stacking, Squeezing, and Unsqueezing Tensors\n",
    "* Reshaping - reshapes and input tensor to a defined shape\n",
    "* View - returns a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
    "* Stacking - combine multiple tensors on top of each other (vstack) or side by side (hstack)\n",
    "* Squeeze - removes all `1` dimensions from a tensor\n",
    "* Unsqueeze - add a `1` dimension to a target tensor\n",
    "* Permute - return a view of the input with dimensions permuted (swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "20d7cd8e-1ae8-4054-afac-0d29bdf04725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]),\n",
       " torch.Size([10]),\n",
       " 1)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1., 11.)\n",
    "x, x.shape, x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "72c34c79-aa71-4e9a-b79d-2ce9576bde56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.,  3.,  4.,  5.],\n",
       "         [ 6.,  7.,  8.,  9., 10.]]),\n",
       " torch.Size([2, 5]),\n",
       " 2)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add an extra dimension\n",
    "x_reshaped = x.reshape(2,5)\n",
    "x_reshaped, x_reshaped.shape, x_reshaped.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "737914da-c914-49bc-aa76-b6ddb94e5e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]),\n",
       " tensor([[ 1.,  2.,  3.,  4.,  5.],\n",
       "         [ 6.,  7.,  8.,  9., 10.]]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, x_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f32816bd-fb7f-4b26-8371-09c168f693bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.],\n",
       "         [ 3.,  4.],\n",
       "         [ 5.,  6.],\n",
       "         [ 7.,  8.],\n",
       "         [ 9., 10.]]),\n",
       " torch.Size([5, 2]),\n",
       " 2)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the view\n",
    "z = x.view(5,2)\n",
    "z, z.shape, z.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "619aac91-0f12-4ff7-be60-039ab2afcaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.],\n",
       "         [ 3.,  4.],\n",
       "         [ 6.,  6.],\n",
       "         [ 7.,  8.],\n",
       "         [ 9., 10.]]),\n",
       " tensor([ 1.,  2.,  3.,  4.,  6.,  6.,  7.,  8.,  9., 10.]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing z changes x (because a view of a tensor shares the same memory as the original input)\n",
    "z[2][0] = 6\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dd8c2b42-16d0-4f2e-be69-581dc0f497eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.,  6.,  6.,  7.,  8.,  9., 10.],\n",
       "        [ 1.,  2.,  3.,  4.,  6.,  6.,  7.,  8.,  9., 10.],\n",
       "        [ 1.,  2.,  3.,  4.,  6.,  6.,  7.,  8.,  9., 10.],\n",
       "        [ 1.,  2.,  3.,  4.,  6.,  6.,  7.,  8.,  9., 10.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "# x_stacked = torch.stack([x, x, x, x], dim=1)\n",
    "x_stacked = torch.stack([x, x, x, x], dim=0)\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ce75cdc0-204c-48f2-86dd-ac264c7a2eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.,  3.,  4.,  6.,  6.,  7.,  8.,  9., 10.],\n",
       "         [ 1.,  2.,  3.,  4.,  6.,  6.,  7.,  8.,  9., 10.],\n",
       "         [ 1.,  2.,  3.,  4.,  6.,  6.,  7.,  8.,  9., 10.],\n",
       "         [ 1.,  2.,  3.,  4.,  6.,  6.,  7.,  8.,  9., 10.]]),\n",
       " tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True]]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_v_stacked = torch.vstack([x, x, x, x])\n",
    "x_v_stacked, x_v_stacked == x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "caea0d9a-e498-45a3-8623-51911201c844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  2.,  3.,  4.,  6.,  6.,  7.,  8.,  9., 10.,  1.,  2.,  3.,  4.,\n",
       "         6.,  6.,  7.,  8.,  9., 10.,  1.,  2.,  3.,  4.,  6.,  6.,  7.,  8.,\n",
       "         9., 10.,  1.,  2.,  3.,  4.,  6.,  6.,  7.,  8.,  9., 10.])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_h_stacked = torch.hstack([x, x, x, x])\n",
    "x_h_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8d908cb1-6a16-413b-a414-3a577d487fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]), 2)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1., 11.)\n",
    "x = x.reshape(1,10)\n",
    "x, x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "25c9e3c0-de3f-4b50-9158-044d209325c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor:\n",
      "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]])\n",
      "Previous shape: torch.Size([1, 10])\n",
      "Squeezed tensor:\n",
      "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n",
      "Squeezed tensor shape: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# torch.squeeze() removes all single dimensions from a target tensor \n",
    "print(\"Previous tensor:\")\n",
    "print(x)\n",
    "print(f\"Previous shape: {x.shape}\")\n",
    "# remove extra dimensions from x_reshaped\n",
    "x_squeezed = torch.squeeze(x)\n",
    "print(\"Squeezed tensor:\")\n",
    "print(x_squeezed)\n",
    "print(f\"Squeezed tensor shape: {x_squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "232906ff-6bf2-42e5-8a39-d0eb7d409c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous target:\n",
      "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n",
      "Previous shape: torch.Size([10])\n",
      "New tensor:\n",
      "tensor([[ 1.],\n",
      "        [ 2.],\n",
      "        [ 3.],\n",
      "        [ 4.],\n",
      "        [ 5.],\n",
      "        [ 6.],\n",
      "        [ 7.],\n",
      "        [ 8.],\n",
      "        [ 9.],\n",
      "        [10.]])\n",
      "New shape: torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "# torch.unsqueeze() adds a single dimension to a target tensor at a specific dim (dimension)\n",
    "print(\"Previous target:\")\n",
    "print(x_squeezed)\n",
    "print(f\"Previous shape: {x_squeezed.shape}\")\n",
    "\n",
    "# add extra dimension with unsqueeze\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=1)\n",
    "print(\"New tensor:\")\n",
    "print(x_unsqueezed)\n",
    "print(f\"New shape: {x_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "de4f0d28-a3d0-4355-a7a2-2f54f5ee1532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of original: torch.Size([224, 224, 3])\n",
      "Size of permuted: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# torch.permute() rearranges the dimensions of a target tensor in a specified order \n",
    "x_original = torch.rand(size=(224, 224, 3))  # [height, width, color channels] \n",
    "\n",
    "# permute the orginal tensor to rearrange the axis (or dim) order\n",
    "x_permuted = torch.permute(x_original, (2, 0, 1))  # we want color channels to be first, then height and then width\n",
    "print(f\"Size of original: {x_original.size()}\")\n",
    "print(f\"Size of permuted: {x_permuted.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "28edd2e6-5746-4aa2-bc03-f61e23927b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2596, 0.4300, 0.5594],\n",
       "         [0.0066, 0.2661, 0.1674],\n",
       "         [0.1085, 0.4798, 0.5917],\n",
       "         ...,\n",
       "         [0.4343, 0.8138, 0.2029],\n",
       "         [0.5538, 0.3319, 0.7467],\n",
       "         [0.5398, 0.6108, 0.6696]],\n",
       "\n",
       "        [[0.3280, 0.4116, 0.5747],\n",
       "         [0.0207, 0.5035, 0.4899],\n",
       "         [0.1617, 0.1149, 0.2835],\n",
       "         ...,\n",
       "         [0.6379, 0.7139, 0.8716],\n",
       "         [0.0690, 0.2961, 0.4525],\n",
       "         [0.6557, 0.4899, 0.5720]],\n",
       "\n",
       "        [[0.0782, 0.1770, 0.5671],\n",
       "         [0.5447, 0.2187, 0.5821],\n",
       "         [0.7875, 0.2080, 0.5751],\n",
       "         ...,\n",
       "         [0.1659, 0.1929, 0.5209],\n",
       "         [0.4919, 0.5379, 0.7947],\n",
       "         [0.9284, 0.3257, 0.8464]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5578, 0.5662, 0.1272],\n",
       "         [0.8086, 0.5570, 0.0402],\n",
       "         [0.9345, 0.9793, 0.0226],\n",
       "         ...,\n",
       "         [0.3210, 0.7814, 0.6712],\n",
       "         [0.3666, 0.9502, 0.7682],\n",
       "         [0.3343, 0.8653, 0.7308]],\n",
       "\n",
       "        [[0.8575, 0.3845, 0.6697],\n",
       "         [0.6101, 0.2841, 0.8973],\n",
       "         [0.4203, 0.4735, 0.7398],\n",
       "         ...,\n",
       "         [0.1323, 0.5890, 0.5587],\n",
       "         [0.1146, 0.9195, 0.2081],\n",
       "         [0.4239, 0.3851, 0.1393]],\n",
       "\n",
       "        [[0.7548, 0.7242, 0.3802],\n",
       "         [0.6666, 0.0808, 0.2811],\n",
       "         [0.7686, 0.1190, 0.9872],\n",
       "         ...,\n",
       "         [0.6016, 0.0017, 0.6500],\n",
       "         [0.7975, 0.3152, 0.9803],\n",
       "         [0.9797, 0.6713, 0.1347]]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7ad6052e-0dc5-4669-a1c5-b46a166b198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_original[0, 0, 0] = 5794"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4c11effd-a96b-4a7c-91df-a6b2fe49a391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5794.), tensor(5794.))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_original[0, 0, 0], x_permuted[0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb053eca-bb96-41c7-be84-5d31271cdd1d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Indexing (Selecting)\n",
    "Indexing with Pytorch is similar to indexing with Numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6264c4fc-76c2-4933-93a7-1324ff3ef2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(start=1, end=10).reshape(1, 3, 3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "200eec0f-be71-429a-9c7b-d1b622d32796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's index on our new tensor (dim=0)\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "761cec8f-0813-47b9-bdd6-fa74fb5b8a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's index on middle bracket (dim=1)\n",
    "x[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "03febe9a-d80d-4aa0-b7f7-bbff21e1ded8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(6), tensor(9))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's index on the innermost bracket (dim=2)\n",
    "x[0, 1, 2], x[0][2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0283d641-3841-43f5-a0c2-2c17b3001454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also use \":\" to select all of a target dimension\n",
    "x[0, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a41a2720-616b-49c3-92bc-6a1269c48595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of 0th and 1st dim, but only index 1 of 2nd dim\n",
    "x[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "259de34b-774f-4e1b-9a1a-428c53911608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of 0th dim, but only index 1 of 1st and 2nd dim\n",
    "x[:, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "999dc11c-b07e-4ee8-860b-134319f76267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get index 0 of 0th and 1st dim, but all values of 2nd dim\n",
    "x[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "55ae8f8b-760a-4bc8-b2b8-6be48bd0e708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index on x to return 3, 6, 9\n",
    "x[0, :, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cd15bb-6934-4a4e-9efd-4529cdc386f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### PyTorch and Numpy\n",
    "Numpy is a very popular scientific computing library in Python. <br/>\n",
    "And because of this, PyTorch has the functionality to interact with it.\n",
    "* Data in numpy array, want in Pytorch tensor => `torch.from_numpy(ndarray)`\n",
    "* Pytorch tensor to numpy => `torch.Tensor.numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "af8a67cc-ce9e-4222-917a-d75687a862e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]), tensor([1., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.arange(1., 8.)\n",
    "# WARNING: when converting from numpy -> pytorch, pytorch reflects numpy's default dtype which is float64 unless specified otherwise\n",
    "tensor = torch.from_numpy(array).type(torch.float32)\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "eaa98809-33a5-4dbc-ab2a-feb8c9b54cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), torch.float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.dtype, tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c59a16ad-4f71-4be4-a782-466c4c5604d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]), tensor([1., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the value of array, what will this do to the tensor?\n",
    "array = array + 1\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "825f2804-6ab0-468d-8cd6-0052cd2d720e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to Numpy array\n",
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4a97c3ec-dc32-4a0c-ac75-08820a9ac5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the tensor, what happens to the numpy array?\n",
    "tensor = tensor + 1\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a40070-027d-4d8a-97bc-cd03a2d67d18",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Reproducibility (trying to take out the random from random)\n",
    "In short how a neural network Learns:<br />\n",
    "`start with random nos => tensor operations => update random nos to try and make them better representations of the data => again ...` <br />\n",
    "To reduce the randomness in neural networks and Pytorch, comes the concept of **random seed**<br />\n",
    "Essentially what the random seed does is \"flavor\" the randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7cdeeb97-e0f3-4f85-8f11-6c7216ecdae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2651, 0.1850, 0.0774, 0.0893],\n",
      "        [0.5713, 0.7317, 0.1043, 0.2575],\n",
      "        [0.3605, 0.7210, 0.6769, 0.4966]])\n",
      "tensor([[0.4391, 0.9958, 0.7561, 0.4034],\n",
      "        [0.0123, 0.0866, 0.1295, 0.2616],\n",
      "        [0.8562, 0.5262, 0.0838, 0.3040]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "# Create two random tensors \n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "print(random_tensor_A)\n",
    "print(random_tensor_B)\n",
    "print(random_tensor_A == random_tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e932ecbf-a299-4570-ae5d-ac82cf9ac50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# Let's make some random but reproducible tensors \n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(random_tensor_C)\n",
    "print(random_tensor_D)\n",
    "print(random_tensor_C == random_tensor_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a10d62e-d863-42f8-9f7d-1832d6d29daa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Running tensors and Pytorch objects on the GPUs (and making faster computations)\n",
    "GPUs = faster computation on numbers, thanks to MPS + Apple hardware + PyTorch working behind the scenes to make everything fast.<br />\n",
    "**Getting a GPU**\n",
    "- Use Google Colab for a free GPU\n",
    "- Use your own GPU - requires investment in hardware\n",
    "- Use Cloud Computing like GCP, AWS, Azure, these services allow us to rent computers on the cloud and access them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "11c50c94-c2d0-4f58-a9d1-edcca0e17e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for GPU access with Pytorch\n",
    "torch.backends.mps.is_built(), torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b8a13c-9f70-49ae-9155-727f6cfe27ab",
   "metadata": {},
   "source": [
    "For PyTorch since it's capable of running compute on GPU or CPU, it's best practice to setup device agnostic code since there is no guarantee that the GPU will be available for us all the time.<br />\n",
    "E.g, run on GPU if available else default to CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f436754b-b94c-4388-978f-1735c3d8618c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device agnostic code \n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "086f1a16-4ab9-4011-bf0b-3b17de5c3c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of devices\n",
    "torch.mps.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f0819f-4e69-4e12-9d0e-1bec28839389",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Putting tensors and models on the GPU\n",
    "The reason we want our tensors/models on GPU is because using a GPU results in faster computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "dcf20148-0306-4040-b8be-04013350353a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor (default on CPU)\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "print(tensor, tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6616b029-b0cc-42f7-875b-e7228ac9a742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='mps:0')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move tensor to GPU (if available)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd825e4-fbfe-4160-8b9b-153ac966ccab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Moving tensors back to the CPU\n",
    "If tensor is on GPU, it can't be tranformed into a numpy array as numpy only works on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "316d5878-768f-4aa7-a1d5-9e372f2ec28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below line of code will give us a TypeError as our tensor is on GPU and numpy arrays only work on CPU\n",
    "# tensor_on_gpu.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3b50cdd5-1d88-4ac8-85fb-c9508a841e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to fix the GPU tensor with NumPy issue, we can first set it to CPU\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "982a1b7c-8a6f-450e-a831-e8b310b27626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='mps:0')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_on_gpu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
