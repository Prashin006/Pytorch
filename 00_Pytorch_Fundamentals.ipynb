{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bedc47d-8679-4853-b8ad-e5952b9fe309",
   "metadata": {},
   "source": [
    "### Imports to test the conda environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b71ba2d-43f5-4afa-8a49-2edeb4c41515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb5a3447-7af9-466f-95a1-560092aefd1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c1fa4d-02bb-4d07-b43d-51c1a607ea1a",
   "metadata": {},
   "source": [
    "### Using MPS (Metal Performance Shaders) for utilizing Mac GPU\n",
    "#### Note that the code in this section is specifically for checking whether it is running on a GPU or CPU\n",
    "#### Instead of `torch.backends.mps.is_available()` use `torch.cuda.is_available()` for systems using Nvidia GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e67a49dc-b114-4bfd-bb6f-063765e6c941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal Performance Shaders are available for this system and we are using it to improve performance!\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    print(\"Metal Performance Shaders are available for this system and we are using it to improve performance!\")\n",
    "else:\n",
    "    print(\"Oops! Metal Performance Shaders aren't available!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "514d61c2-a146-406c-a455-936197f22d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is MPS built? True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Is MPS built? {torch.backends.mps.is_built()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16a72ccd-4db6-4aad-8bc9-e5cf61826550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is MPS available? True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Is MPS available? {torch.backends.mps.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80132e7a-337f-4c92-b83b-09fec46d4802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps\n"
     ]
    }
   ],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f85f3ed-2f3a-4a12-9c4d-c94f12f188b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(size=(3,4)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f3a34fd-b20d-4740-89b3-2e696003d4fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1069, 0.4077, 0.5234, 0.4319],\n",
       "        [0.7820, 0.9949, 0.9309, 0.0054],\n",
       "        [0.2860, 0.0943, 0.7818, 0.5585]], device='mps:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d54281c-05ee-4e0a-a708-1fd21ca00621",
   "metadata": {},
   "source": [
    "### Creating Scalars and Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3124d583-da59-4ea2-a340-871f841031e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfeb720d-b149-46f8-af18-40b79a6233fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7408f3fc-797e-4525-9e0b-0ab50635caa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get tensor back as Python int\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7170dc7-f725-49a0-bf1d-3634245785c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77dc644d-5b08-4416-8b55-3528cc343811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd29d7ba-f3cf-499e-89d9-df0bab22e4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d0918d-4e66-45aa-ae2f-9f2264a3053c",
   "metadata": {},
   "source": [
    "### Creating MATRIX and TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe4da4ea-d688-4305-a741-73e431d60472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix\n",
    "MATRIX = torch.tensor([[7, 8],\n",
    "                       [9, 10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f445a069-fb86-44e4-a249-2ee703a853d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([2, 2]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim, MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cb3bc2c-19cb-48fe-bc84-baa5895974ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 3,  6,  9],\n",
       "         [ 2,  4, 56]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensors\n",
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                       [3, 6, 9],\n",
    "                       [2, 4, 56]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea1e9348-6061-43d2-bee9-b25cbe3243b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim, TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f36c0cb-3dfe-4afc-a66e-629d8f8c026f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1,  2,  3],\n",
       "         [ 3,  6,  9],\n",
       "         [ 2,  4, 56]]),\n",
       " tensor([3, 6, 9]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0], TENSOR[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8eeae132-f652-4068-99d2-341afcd931ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "520303f9-5551-4438-8a59-ad277d93de18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0][0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98c8631-2086-4c46-8031-b302dac0c6d2",
   "metadata": {},
   "source": [
    "### Creating Random Tensors\n",
    "#### Why random tensors?\n",
    "- Random tensors are important because the way many neural networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data\n",
    "- `Start with random nos => look at data => update the random nos => look at data => update the random nos ...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8303381c-da52-43a3-ad15-5a6e88914f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6788, 0.5172, 0.0668, 0.8690],\n",
       "        [0.9317, 0.4923, 0.2338, 0.8474],\n",
       "        [0.8352, 0.7282, 0.9893, 0.1773]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size (3,4)\n",
    "random_tensor = torch.rand(3, 4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "958dd31d-8f95-404c-b419-71aa30c0ce05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([3, 4]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim, random_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14992697-54ee-4949-b4d4-7a47a24c820a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6037, 0.2488, 0.3747,  ..., 0.9455, 0.8129, 0.5911],\n",
       "         [0.5111, 0.2793, 0.5101,  ..., 0.6549, 0.9096, 0.2859],\n",
       "         [0.1848, 0.8459, 0.6746,  ..., 0.2459, 0.5931, 0.5557],\n",
       "         ...,\n",
       "         [0.0262, 0.2304, 0.2962,  ..., 0.7271, 0.0339, 0.8868],\n",
       "         [0.6167, 0.6264, 0.1927,  ..., 0.7007, 0.3688, 0.8348],\n",
       "         [0.6827, 0.1436, 0.9985,  ..., 0.7147, 0.6702, 0.8565]],\n",
       "\n",
       "        [[0.4616, 0.6842, 0.4523,  ..., 0.4077, 0.4759, 0.9985],\n",
       "         [0.4143, 0.4041, 0.6947,  ..., 0.6115, 0.5864, 0.4255],\n",
       "         [0.5155, 0.3724, 0.3577,  ..., 0.8137, 0.8224, 0.9704],\n",
       "         ...,\n",
       "         [0.0891, 0.6804, 0.6295,  ..., 0.6401, 0.0364, 0.6675],\n",
       "         [0.5047, 0.9933, 0.1637,  ..., 0.1668, 0.1266, 0.3613],\n",
       "         [0.3937, 0.8370, 0.6882,  ..., 0.5882, 0.7689, 0.1185]],\n",
       "\n",
       "        [[0.8530, 0.0777, 0.1031,  ..., 0.0756, 0.3372, 0.1099],\n",
       "         [0.6023, 0.8756, 0.6167,  ..., 0.8347, 0.0583, 0.2795],\n",
       "         [0.0619, 0.4728, 0.4417,  ..., 0.0027, 0.4181, 0.3019],\n",
       "         ...,\n",
       "         [0.9802, 0.5296, 0.2945,  ..., 0.6341, 0.9343, 0.2310],\n",
       "         [0.5730, 0.5638, 0.0153,  ..., 0.2739, 0.9711, 0.3597],\n",
       "         [0.0230, 0.5345, 0.4934,  ..., 0.6271, 0.8536, 0.2993]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor with a similar shape to an image tensor\n",
    "random_image_size_tensor = torch.rand(size=(3,224,224))  # height, width, color_channels (R, G, B)\n",
    "random_image_size_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b412e2-a123-42d6-9cfd-ffa17ef2a470",
   "metadata": {},
   "source": [
    "### Creating zeroes and ones tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f44f17b-c2da-4306-8df7-49b9f0ad59d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(3, 4)\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e5d2b68-230b-4113-8e65-610b2a64842d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros * random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6e51f7b-162e-412f-b328-b57db4ac87e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tensor of ones\n",
    "ones = torch.ones(size=(3, 4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b9dce65-6611-4056-8703-7a9a37bd4b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones*random_tensor == random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa092dbf-f06b-4c87-9696-c80d5f2c8fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.float32, torch.float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype, zeros.dtype, random_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3f59b1-d496-4c86-9742-fcbf51d0f934",
   "metadata": {},
   "source": [
    "### Creating a range of tensors and tensor-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72d644f4-7609-4496-bd39-8794473df2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below range method is deprecated\n",
    "# torch.range(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f6477fa-5fbe-4180-b4db-3c7a222b31ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.int64, tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(1,10)\n",
    "a.dtype,a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5603035-5625-430c-ae3f-1163577a822d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,  77, 154, 231, 308, 385, 462, 539, 616, 693, 770, 847, 924])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_77 = torch.arange(start=0,end=1000,step=77)\n",
    "step_77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78cf9a19-b5a7-4dd4-ac0c-207c435d3b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), torch.int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros_like_77 = torch.zeros_like(input=step_77)\n",
    "zeros_like_77, zeros_like_77.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aea9a2ed-8860-413b-acb5-444f05e4e4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " torch.int64,\n",
       " 1,\n",
       " torch.Size([13]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones_like_77 = torch.ones_like(input=step_77)\n",
    "ones_like_77, ones_like_77.dtype, ones_like_77.ndim, ones_like_77.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f2d9968-ad64-44f0-bc62-c56faae81ee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1000 // 77"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd73ef7f-eff8-4db5-8a1a-fd3ba051b79d",
   "metadata": {},
   "source": [
    "### Tensor Datatypes\n",
    "**Note:** Tensor Datatypes are one of the big 3 errors with Pytorch and Deep Learning that we may run into\n",
    "1. Tensors not on right datatype\n",
    "2. Tensors not in right shape\n",
    "3. Tensors not on right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7db2a457-1315-40d9-9e90-bef5c57a5870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.0000, 3.0000, 9.0000, 6.8000], device='mps:0'), torch.float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor = torch.tensor([1.0,3.0,9.0,6.8],\n",
    "                               dtype=torch.float32,  # what datatype is the tensor (eg, float32 or float16)\n",
    "                               device='mps',  # what device the tensor is on (eg, cpu, gpu)\n",
    "                               requires_grad=False)  # whether or not to track gradients with this tensor operations \n",
    "float_32_tensor, float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa486ff7-fdb3-49cc-af7e-26d36648840b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.0000, 3.0000, 9.0000, 6.8008], device='mps:0', dtype=torch.float16),\n",
       " device(type='mps', index=0),\n",
       " device(type='mps', index=0))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "float_16_tensor, float_16_tensor.device, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e57e5fe4-0eee-4f53-85c5-3f95b02b7f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  9.0000, 81.0000, 46.2453], device='mps:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor * float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ccdb097a-151d-4fb9-b7c8-cb7374e8a899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, device(type='mps', index=0))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_mul_tensor = float_16_tensor * float_32_tensor\n",
    "float_mul_tensor.dtype, float_mul_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c4d77dfa-275b-41dd-abb5-89ff67089c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 9, 6], device='mps:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = float_32_tensor.type(torch.int32)\n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ba5c5fef-acf4-43ac-ad4c-3e7b7418409e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  9.0000, 81.0000, 40.8125], device='mps:0',\n",
       "       dtype=torch.float16)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor * float_16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b84da6a5-3d4b-4ff6-bf4e-25232b81b440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.0000,  9.0000, 81.0000, 40.8000], device='mps:0'), torch.float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_another_mul_tensor = int_32_tensor * float_32_tensor\n",
    "float_another_mul_tensor, float_another_mul_tensor.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7638086d-eeb9-4812-8c0d-5b1a310d218e",
   "metadata": {},
   "source": [
    "### Getting Information From Tensors\n",
    "#### To get the datatype simply type `tensor.dtype`\n",
    "#### To get the shape of a tensor simply type `tensor.shape`\n",
    "#### To get the device of a tensor simply type `tensor.device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da7f8987-1eb4-473d-b458-5e4e541a678a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2678, 0.7564, 0.6530, 0.2688],\n",
       "        [0.7860, 0.2127, 0.3016, 0.9078],\n",
       "        [0.1607, 0.7692, 0.7162, 0.0103]], device='mps:0')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor = torch.rand(size=(3, 4), device='mps')\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4c4e9f1f-6816-43e5-aa1e-07fda1418cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datatype\n",
    "some_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fd213820-afe3-400d-9f61-1a6b298a2f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4]), 2, torch.Size([3, 4]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape and no of dimensions\n",
    "some_tensor.size(), some_tensor.ndim, some_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "da18a1d4-5129-4c90-b1a8-85987ab65589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device\n",
    "some_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ce1cfa-f13a-43e9-97d7-a31098db59ad",
   "metadata": {},
   "source": [
    "### Manipulating Tensors (Tensor operations)\n",
    "Tensor Operations include:\n",
    "- Addition\n",
    "- Subtractions\n",
    "- Multiplication (element-wise)\n",
    "- Division\n",
    "- Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "564ff1a6-e23d-4a02-a5a9-8a611a2bfc0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13], device='mps:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor and add 10 to it\n",
    "tensor = torch.tensor([1, 2, 3], dtype=torch.int32, device='mps')\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4f2caf2e-c133-4aa2-a4b3-ba56a67dc3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30], device='mps:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply tensor by 10 and reassign it back\n",
    "tensor *= 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8e06d02a-5af0-4982-b4bd-9958a1c7d1e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3.], device='mps:0'), torch.float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divide tensor by 10 and reassign it back\n",
    "tensor = tensor / 10\n",
    "tensor, tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "158e4201-faae-42cb-b15e-8f31558c7a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([100., 200., 300.], device='mps:0')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try out Pytorch built-in functions\n",
    "torch.mul(tensor, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a2f7a4d9-6b93-430c-a721-1b1d8eeb0cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], device='mps:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9eb4a7dd-c24b-4be2-993a-507e4e445dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0100, 0.0200, 0.0300], device='mps:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.div(tensor, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "46034521-a352-4888-80d5-01ce109b4c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1001., 1002., 1003.], device='mps:0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(tensor, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fdaef2f2-40a2-4bf6-902d-1ed20b8c293d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.], device='mps:0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.subtract(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fdcaa9ce-6c3b-4c31-9c56-5e1a6a00b6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], device='mps:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50abe7ad-9d67-4137-b2d8-a8efb353f812",
   "metadata": {},
   "source": [
    "### Matrix Multiplication\n",
    "Two main ways of performing multiplication in neural networks and deep learning are:\n",
    "1. Element-wise multiplication\n",
    "2. Matrix Multiplication\n",
    "\n",
    "There are two main rules that need to be satisfied in order to perform matrix multiplication:\n",
    "1. **Inner dimensions** must match\n",
    "   * `(3, 2) @ (2, 3)` will work\n",
    "   * `(3, 2) @ (3, 2)` won't work`\n",
    "2. The resulting matrix has the shape of **outer dimensions**\n",
    "   * `(2, 3) @ (3, 2)` => `(2, 2)`\n",
    "   * `(3, 2) @ (2, 3)` => `(3, 3)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "243c0e27-129d-4610-b265-4123fb3bcf33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.9676, 0.8652, 0.1710],\n",
       "        [0.2197, 0.5790, 0.9255, 0.6895],\n",
       "        [0.4778, 0.2626, 0.6450, 0.9777]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1 = torch.rand(size=(3,4))\n",
    "tensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1bfe17ee-f83d-4946-9cab-10a2b250c806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3507, 0.1795, 0.9785],\n",
       "        [0.8709, 0.0628, 0.9833],\n",
       "        [0.5871, 0.5504, 0.8028],\n",
       "        [0.4669, 0.5238, 0.1149]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2 = torch.rand(size=(4,3))\n",
    "tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "38a8b4eb-5ebe-4bcd-ba9a-1c0a73d29357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6059, 0.7163, 2.1551],\n",
       "        [1.4466, 0.9464, 1.6066],\n",
       "        [1.2314, 0.9693, 1.3560]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor3 = torch.matmul(tensor1, tensor2)\n",
    "tensor3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "87b57d3c-bcc0-4efb-84a4-b2eccfc4cbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten = torch.tensor([1, 2, 3], dtype=torch.int32)\n",
    "ten * ten  # element wise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6c8bea17-4d5a-4af7-a03c-09de37b16ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14, dtype=torch.int32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(ten, ten)  # matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e20be662-0768-4cfb-af60-f0ccf13367ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14, dtype=torch.int32)\n",
      "CPU times: user 2.21 ms, sys: 2.02 ms, total: 4.23 ms\n",
      "Wall time: 2.41 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "value = 0\n",
    "for i in range(len(ten)):\n",
    "    value += ten[i] * ten[i]\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "df693588-236b-480e-a5e0-d211ee4d4804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14, dtype=torch.int32) cpu\n",
      "CPU times: user 1.19 ms, sys: 1.53 ms, total: 2.73 ms\n",
      "Wall time: 1.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "value = torch.matmul(ten, ten)\n",
    "print(value, value.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8610353f-e0fc-492d-9baf-2ac47b8be487",
   "metadata": {},
   "source": [
    "### One of the most common error in Deep Learning: shape errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f0f5af5a-da84-455a-a10d-3c447e548609",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 8\u001b[0m\n\u001b[1;32m      2\u001b[0m tensor_A \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m      3\u001b[0m                          [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m],\n\u001b[1;32m      4\u001b[0m                          [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m]])\n\u001b[1;32m      5\u001b[0m tensor_B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[1;32m      6\u001b[0m                          [\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m11\u001b[39m],\n\u001b[1;32m      7\u001b[0m                          [\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m12\u001b[39m]])\n\u001b[0;32m----> 8\u001b[0m torch\u001b[38;5;241m.\u001b[39mmm(tensor_A, tensor_B)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# Shapes for matrix multiplication\n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]])\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11],\n",
    "                         [9, 12]])\n",
    "# Below line of code will give a RuntimeError as the shapes of the two tensors for multiplication do not match\n",
    "# torch.mm(tensor_A, tensor_B)  # torch.mm() is same as torch.matmul() (it's an alias for writing less code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d19b733-593a-4279-a932-663929d93062",
   "metadata": {},
   "source": [
    "To fix our tensor shape issues, we can manipulate the shape of one of our tensors using a **transpose**.<br />\n",
    "A **transpose** switches the axes or dimensions of a given tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "15a1bf49-f779-4bb5-834a-a4414ed2ebc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7, 10],\n",
       "         [ 8, 11],\n",
       "         [ 9, 12]]),\n",
       " tensor([[ 7,  8,  9],\n",
       "         [10, 11, 12]]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B, tensor_B.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c135fdce-2756-48e9-b0d6-007e888b6668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B.shape, tensor_B.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5449d29c-30bc-4b95-874a-e8a3b42167b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27,  30,  33],\n",
       "        [ 61,  68,  75],\n",
       "        [ 95, 106, 117]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(tensor_A, tensor_B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ca465259-9985-46c9-b5cb-ea0aa15b5b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tensor_A, tensor_B.T).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394a9196-230f-46b8-93fa-4062576c0151",
   "metadata": {},
   "source": [
    "### Finding the min, max, mean, sum etc. (Tensor Aggregation)\n",
    "**Note: the `torch.mean()` function requires a tensor of datatype float32 to work**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8adb66d4-8bc2-417d-85e3-94a1ef6da4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]),\n",
       " torch.Size([10]),\n",
       " torch.int64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(start=0, end=100, step=10)\n",
    "x, x.size(), x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "610b3b5f-af90-4dd0-9db5-01103a466b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), torch.int64)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the min\n",
    "# min = torch.min(x)\n",
    "min = x.min()\n",
    "min, min.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "33b4fa33-2967-44ff-8aa8-4ae4e0157fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), torch.int64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the max\n",
    "# max = torch.max(x)\n",
    "max = x.max()\n",
    "max, max.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1a02ba97-442f-417e-9a58-8e8bcf76f104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the mean\n",
    "# mean = x.mean()\n",
    "# mean\n",
    "# Above lines of code won't work (not the right datatype => mean does not accept long or int64), so we need to typecast the datatype using the dtype keyword\n",
    "# mean function accepts only either a floating point or a complex datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7cc7b217-c423-4b8b-a7c9-5fb805e8a2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(45.)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean = x.mean(dtype=torch.float32)\n",
    "# mean = torch.mean(x, dtype=torch.float32)\n",
    "mean = x.type(torch.float32).mean()\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b9ac4286-5582-4b4e-9268-d219bcc94a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(450), tensor(450))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the Sum\n",
    "torch.sum(x), x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "323382ee-b27a-413e-989f-85f6a567501d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(40), tensor(40))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.median(x), x.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86c882c-db72-4276-9b7e-cb4f279f8225",
   "metadata": {},
   "source": [
    "### Finding positional min and max using argmin and argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8d2a714c-7f90-4357-8fbb-301f9a5261a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(8), tensor(0), tensor(90))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# argmin and argmax => index/position at which the min and max values occur in the tensor\n",
    "x.argmin(), a.argmax(), x[x.argmin()], x[x.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b97dc561-5e34-47f9-a1f3-60622402fd1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.arange(1, 100, step=10)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "af4ce398-b766-4b38-a007-24e7bd508f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(9))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.argmin(), y.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "27ce5e63-3ba8-48b0-9497-7955cb651d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1), tensor(91))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0], y[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2462db3b-eb02-4ba7-a55f-89138b84f5e0",
   "metadata": {},
   "source": [
    "### Reshaping, Viewing, Stacking, Squeezing, and Unsqueezing Tensors\n",
    "* Reshaping - reshapes and input tensor to a defined shape\n",
    "* View - returns a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
    "* Stacking - combine multiple tensors on top of each other (vstack) or side by side (hstack)\n",
    "* Squeeze - removes all `1` dimensions from a tensor\n",
    "* Unsqueeze - add a `1` dimension to a target tensor\n",
    "* Permute - return a view of the input with dimensions permuted (swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "20d7cd8e-1ae8-4054-afac-0d29bdf04725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]),\n",
       " torch.Size([10]),\n",
       " 1)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1., 11.)\n",
    "x, x.shape, x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "72c34c79-aa71-4e9a-b79d-2ce9576bde56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.,  3.,  4.,  5.],\n",
       "         [ 6.,  7.,  8.,  9., 10.]]),\n",
       " torch.Size([2, 5]),\n",
       " 2)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add an extra dimension\n",
    "x_reshaped = x.reshape(2,5)\n",
    "x_reshaped, x_reshaped.shape, x_reshaped.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "737914da-c914-49bc-aa76-b6ddb94e5e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]),\n",
       " tensor([[ 1.,  2.,  3.,  4.,  5.],\n",
       "         [ 6.,  7.,  8.,  9., 10.]]))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, x_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f32816bd-fb7f-4b26-8371-09c168f693bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.],\n",
       "         [ 3.,  4.],\n",
       "         [ 6.,  6.],\n",
       "         [ 7.,  8.],\n",
       "         [ 9., 10.]]),\n",
       " torch.Size([5, 2]),\n",
       " 2)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the view\n",
    "z = x.view(5,2)\n",
    "z, z.shape, z.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "619aac91-0f12-4ff7-be60-039ab2afcaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.],\n",
       "         [ 3.,  4.],\n",
       "         [ 6.,  6.],\n",
       "         [ 7.,  8.],\n",
       "         [ 9., 10.]]),\n",
       " tensor([ 1.,  2.,  3.,  4.,  6.,  6.,  7.,  8.,  9., 10.]))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing z changes x (because a view of a tensor shares the same memory as the original input)\n",
    "z[2][0] = 6\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "dd8c2b42-16d0-4f2e-be69-581dc0f497eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.,  6.,  6.,  7.,  8.,  9., 10.],\n",
       "        [ 1.,  2.,  3.,  4.,  6.,  6.,  7.,  8.,  9., 10.],\n",
       "        [ 1.,  2.,  3.,  4.,  6.,  6.,  7.,  8.,  9., 10.],\n",
       "        [ 1.,  2.,  3.,  4.,  6.,  6.,  7.,  8.,  9., 10.]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "# x_stacked = torch.stack([x, x, x, x], dim=1)\n",
    "x_stacked = torch.stack([x, x, x, x], dim=0)\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ce75cdc0-204c-48f2-86dd-ac264c7a2eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.,  3.,  4.,  6.,  6.,  7.,  8.,  9., 10.],\n",
       "         [ 1.,  2.,  3.,  4.,  6.,  6.,  7.,  8.,  9., 10.],\n",
       "         [ 1.,  2.,  3.,  4.,  6.,  6.,  7.,  8.,  9., 10.],\n",
       "         [ 1.,  2.,  3.,  4.,  6.,  6.,  7.,  8.,  9., 10.]]),\n",
       " tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True]]))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_v_stacked = torch.vstack([x, x, x, x])\n",
    "x_v_stacked, x_v_stacked == x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "caea0d9a-e498-45a3-8623-51911201c844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  2.,  3.,  4.,  6.,  6.,  7.,  8.,  9., 10.,  1.,  2.,  3.,  4.,\n",
       "         6.,  6.,  7.,  8.,  9., 10.,  1.,  2.,  3.,  4.,  6.,  6.,  7.,  8.,\n",
       "         9., 10.,  1.,  2.,  3.,  4.,  6.,  6.,  7.,  8.,  9., 10.])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_h_stacked = torch.hstack([x, x, x, x])\n",
    "x_h_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8d908cb1-6a16-413b-a414-3a577d487fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]), 2)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1., 11.)\n",
    "x = x.reshape(1,10)\n",
    "x, x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "25c9e3c0-de3f-4b50-9158-044d209325c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor:\n",
      "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]])\n",
      "Previous shape: torch.Size([1, 10])\n",
      "Squeezed tensor:\n",
      "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n",
      "Squeezed tensor shape: torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# torch.squeeze() removes all single dimensions from a target tensor \n",
    "print(\"Previous tensor:\")\n",
    "print(x)\n",
    "print(f\"Previous shape: {x.shape}\")\n",
    "# remove extra dimensions from x_reshaped\n",
    "x_squeezed = torch.squeeze(x)\n",
    "print(\"Squeezed tensor:\")\n",
    "print(x_squeezed)\n",
    "print(f\"Squeezed tensor shape: {x_squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "232906ff-6bf2-42e5-8a39-d0eb7d409c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous target:\n",
      "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n",
      "Previous shape: torch.Size([10])\n",
      "New tensor:\n",
      "tensor([[ 1.],\n",
      "        [ 2.],\n",
      "        [ 3.],\n",
      "        [ 4.],\n",
      "        [ 5.],\n",
      "        [ 6.],\n",
      "        [ 7.],\n",
      "        [ 8.],\n",
      "        [ 9.],\n",
      "        [10.]])\n",
      "New shape: torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "# torch.unsqueeze() adds a single dimension to a target tensor at a specific dim (dimension)\n",
    "print(\"Previous target:\")\n",
    "print(x_squeezed)\n",
    "print(f\"Previous shape: {x_squeezed.shape}\")\n",
    "\n",
    "# add extra dimension with unsqueeze\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=1)\n",
    "print(\"New tensor:\")\n",
    "print(x_unsqueezed)\n",
    "print(f\"New shape: {x_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "de4f0d28-a3d0-4355-a7a2-2f54f5ee1532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of original: torch.Size([224, 224, 3])\n",
      "Size of permuted: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# torch.permute() rearranges the dimensions of a target tensor in a specified order \n",
    "x_original = torch.rand(size=(224, 224, 3))  # [height, width, color channels] \n",
    "\n",
    "# permute the orginal tensor to rearrange the axis (or dim) order\n",
    "x_permuted = torch.permute(x_original, (2, 0, 1))  # we want color channels to be first, then height and then width\n",
    "print(f\"Size of original: {x_original.size()}\")\n",
    "print(f\"Size of permuted: {x_permuted.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "28edd2e6-5746-4aa2-bc03-f61e23927b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5794, 0.2707, 0.1589],\n",
       "         [0.3553, 0.9755, 0.2418],\n",
       "         [0.4787, 0.2679, 0.2225],\n",
       "         ...,\n",
       "         [0.9518, 0.7675, 0.6940],\n",
       "         [0.0385, 0.3197, 0.2775],\n",
       "         [0.3808, 0.2049, 0.8661]],\n",
       "\n",
       "        [[0.0470, 0.0735, 0.5573],\n",
       "         [0.2632, 0.7890, 0.3702],\n",
       "         [0.6268, 0.1735, 0.6736],\n",
       "         ...,\n",
       "         [0.3458, 0.2000, 0.8444],\n",
       "         [0.4477, 0.1974, 0.5353],\n",
       "         [0.2676, 0.7196, 0.5361]],\n",
       "\n",
       "        [[0.5860, 0.4519, 0.0947],\n",
       "         [0.4106, 0.6249, 0.9092],\n",
       "         [0.6367, 0.6177, 0.7343],\n",
       "         ...,\n",
       "         [0.8405, 0.7043, 0.2533],\n",
       "         [0.8434, 0.9172, 0.6043],\n",
       "         [0.8397, 0.7613, 0.8062]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.6710, 0.4934, 0.6663],\n",
       "         [0.3325, 0.4705, 0.1920],\n",
       "         [0.2146, 0.5091, 0.1292],\n",
       "         ...,\n",
       "         [0.9231, 0.6592, 0.7966],\n",
       "         [0.9909, 0.9301, 0.2520],\n",
       "         [0.8145, 0.1868, 0.2490]],\n",
       "\n",
       "        [[0.5620, 0.2562, 0.0303],\n",
       "         [0.7541, 0.0193, 0.6444],\n",
       "         [0.5529, 0.1395, 0.8300],\n",
       "         ...,\n",
       "         [0.0993, 0.1604, 0.8036],\n",
       "         [0.3824, 0.0200, 0.4470],\n",
       "         [0.0016, 0.3037, 0.6999]],\n",
       "\n",
       "        [[0.6287, 0.4848, 0.4184],\n",
       "         [0.9549, 0.8742, 0.8382],\n",
       "         [0.1507, 0.0267, 0.3853],\n",
       "         ...,\n",
       "         [0.3826, 0.9500, 0.4510],\n",
       "         [0.8571, 0.4816, 0.3859],\n",
       "         [0.6004, 0.0549, 0.4639]]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7ad6052e-0dc5-4669-a1c5-b46a166b198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_original[0, 0, 0] = 5794"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4c11effd-a96b-4a7c-91df-a6b2fe49a391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5794.), tensor(5794.))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_original[0, 0, 0], x_permuted[0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb053eca-bb96-41c7-be84-5d31271cdd1d",
   "metadata": {},
   "source": [
    "### Indexing (Selecting)\n",
    "Indexing with Pytorch is similar to indexing with Numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6264c4fc-76c2-4933-93a7-1324ff3ef2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(start=1, end=10).reshape(1, 3, 3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "200eec0f-be71-429a-9c7b-d1b622d32796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's index on our new tensor (dim=0)\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "761cec8f-0813-47b9-bdd6-fa74fb5b8a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's index on middle bracket (dim=1)\n",
    "x[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "03febe9a-d80d-4aa0-b7f7-bbff21e1ded8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(6), tensor(9))"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's index on the innermost bracket (dim=2)\n",
    "x[0, 1, 2], x[0][2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0283d641-3841-43f5-a0c2-2c17b3001454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also use \":\" to select all of a target dimension\n",
    "x[0, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a41a2720-616b-49c3-92bc-6a1269c48595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of 0th and 1st dim, but only index 1 of 2nd dim\n",
    "x[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "259de34b-774f-4e1b-9a1a-428c53911608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of 0th dim, but only index 1 of 1st and 2nd dim\n",
    "x[:, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "999dc11c-b07e-4ee8-860b-134319f76267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get index 0 of 0th and 1st dim, but all values of 2nd dim\n",
    "x[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "55ae8f8b-760a-4bc8-b2b8-6be48bd0e708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index on x to return 3, 6, 9\n",
    "x[0, :, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cd15bb-6934-4a4e-9efd-4529cdc386f3",
   "metadata": {},
   "source": [
    "### PyTorch and Numpy\n",
    "Numpy is a very popular scientific computing library in Python. <br/>\n",
    "And because of this, PyTorch has the functionality to interact with it.\n",
    "* Data in numpy array, want in Pytorch tensor => `torch.from_numpy(ndarray)`\n",
    "* Pytorch tensor to numpy => `torch.Tensor.numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "af8a67cc-ce9e-4222-917a-d75687a862e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]), tensor([1., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.arange(1., 8.)\n",
    "# WARNING: when converting from numpy -> pytorch, pytorch reflects numpy's default dtype which is float64 unless specified otherwise\n",
    "tensor = torch.from_numpy(array).type(torch.float32)\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "eaa98809-33a5-4dbc-ab2a-feb8c9b54cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), torch.float32)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.dtype, tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c59a16ad-4f71-4be4-a782-466c4c5604d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]), tensor([1., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the value of array, what will this do to the tensor?\n",
    "array = array + 1\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825f2804-6ab0-468d-8cd6-0052cd2d720e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
